{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "print(password)\n",
    "from modules.login_module import logIn, launch_to_homescreen, create_directory\n",
    "from modules.download_files_module import request_report_process, download_loop_missing, download_process,  move_files_over, unzip_xlsx_file, unzip_files_in_same_dir, move_xlsx_files\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, NoSuchWindowException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules import sql_query_module\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "today_date = datetime.now()\n",
    "formatted_month_day_year = today_date.strftime(\"%m_%d_%y\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "logging.basicConfig(filename='ELPAC_SBAC_results.log', level=logging.INFO,\n",
    "                   format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',force=True)\n",
    "logging.info('\\n\\n-------------ELPAC_SBAC_results new instance log')\n",
    "\n",
    "#create file_download dir, and establish download directory\n",
    "create_directory('file_downloads')\n",
    "create_directory(f'file_downloads\\\\sbac\\\\{formatted_month_day_year}')\n",
    "create_directory(f'file_downloads\\\\elpac\\\\{formatted_month_day_year}')\n",
    "\n",
    "# Set up Chrome options\n",
    "download_directory = os.getcwd() + f'\\\\file_downloads\\\\elpac\\\\{formatted_month_day_year}'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory' : download_directory,\n",
    "         'profile.default_content_setting_values.automatic_downloads': 1,\n",
    "         'profile.content_settings.exceptions.automatic_downloads.*.setting': 1}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options = chrome_options)\n",
    "\n",
    "logIn(username, password, driver)\n",
    "launch_to_homescreen(driver)\n",
    "\n",
    "coord_list = ['LEA CAASPP Coordinator at Alain Leroy Locke College Preparatory Academy',\n",
    " 'LEA CAASPP Coordinator at Animo City of Champions Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo Compton Charter',\n",
    " 'LEA CAASPP Coordinator at Animo Ellen Ochoa Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Florence-Firestone Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Inglewood Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo Jackie Robinson High',\n",
    " 'LEA CAASPP Coordinator at Animo James B. Taylor Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Jefferson Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Leadership High',\n",
    " 'LEA CAASPP Coordinator at Animo Legacy Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Mae Jemison Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Pat Brown',\n",
    " 'LEA CAASPP Coordinator at Animo Ralph Bunche Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo South Los Angeles Charter',\n",
    " 'LEA CAASPP Coordinator at Animo Venice Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo Watts College Preparatory Academy',\n",
    " 'LEA CAASPP Coordinator at Oscar De La Hoya Animo Charter High',\n",
    " 'LEA ELPAC Coordinator at Alain Leroy Locke College Preparatory Academy',\n",
    " 'LEA ELPAC Coordinator at Animo City of Champions Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo Compton Charter',\n",
    " 'LEA ELPAC Coordinator at Animo Ellen Ochoa Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Florence-Firestone Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Inglewood Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo Jackie Robinson High',\n",
    " 'LEA ELPAC Coordinator at Animo James B. Taylor Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Jefferson Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Leadership High',\n",
    " 'LEA ELPAC Coordinator at Animo Legacy Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Mae Jemison Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Pat Brown',\n",
    " 'LEA ELPAC Coordinator at Animo Ralph Bunche Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo South Los Angeles Charter',\n",
    " 'LEA ELPAC Coordinator at Animo Venice Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo Watts College Preparatory Academy',\n",
    " 'LEA ELPAC Coordinator at Oscar De La Hoya Animo Charter High']\n",
    "\n",
    "elpac_coordinators = [coord for coord in coord_list if 'ELPAC' in coord]\n",
    "caaspp_coordinators = [coord for coord in coord_list if 'CAASPP' in coord]\n",
    "\n",
    "#This exists when passing names into the requested reports, as a subset. Change list into a set to only retain unique schools\n",
    "school_report_names = [entry.split(' at ', 1)[1] for entry in elpac_coordinators]\n",
    "school_report_names = list(set(school_report_names))\n",
    "\n",
    "# ---------------------------------------SBAC Files Request and Download\n",
    "\n",
    "# Call the function, school report names variable is called for just school name\n",
    "#Equivalent of Student Score Data File\n",
    "request_report_process(driver, 'SBAC', 'CAASPP_Student_Score_Data_Extract_Report', caaspp_coordinators, '2023')\n",
    "download_process(school_report_names, '2023 CAASPP Student Score Data File By Enrolled LEA', driver) \n",
    "\n",
    "#This is here three times to see if anything got skipped the first time. Initial dir is set at ELPAC only to move the files over to SBAC dir\n",
    "#Will run 5 times\n",
    "\n",
    "time.sleep(10) #implemented to give time for files to download\n",
    "download_loop_missing(f'elpac\\\\{formatted_month_day_year}', '2023 CAASPP Student Score Data File By Enrolled LEA', driver)\n",
    "\n",
    "#This moves the files from ELPAC  timestamp dir to SBAC timestamp dir. \n",
    "#This is because the download dir cannot be changed in Selenium\n",
    "move_files_over()\n",
    "\n",
    "# --------------------------------------------ELPAC Files Request and Download\n",
    "\n",
    "driver.switch_to.default_content()\n",
    "request_report_process(driver, 'ELPAC', 'Student_Results_Report_Student_Score_Data_Extract', elpac_coordinators, '2023')\n",
    "download_process(school_report_names, '2023 Summative ELPAC and Summative Alternate ELPAC Student Score Data File By Enrolled LEA', driver) \n",
    "\n",
    "time.sleep(10) #implemented to give time for files to download\n",
    "#This is here three times to see if anything got skipped the first time. \n",
    "#Dir remains ELPAC for constant download directory\n",
    "download_loop_missing(f'elpac\\\\{formatted_month_day_year}', '2023 Summative ELPAC and Summative Alternate ELPAC Student Score Data File By Enrolled LEA', driver)\n",
    "\n",
    "#Close out driver window once done\n",
    "driver.close()\n",
    "\n",
    "#Takes 14 mins to run up to this point\n",
    "# -----------------------------------------Unzip the Files and Move them to the P-Drive in this location 'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing'\n",
    "unzip_files_in_same_dir('elpac')\n",
    "unzip_files_in_same_dir('sbac')\n",
    "\n",
    "#Keeps raw zip files in the same dir. Only moves over xlsx files\n",
    "try:\n",
    "    move_xlsx_files('sbac')\n",
    "    logging.info('Moved SBAC XLSX files to p-drive')\n",
    "except:\n",
    "    logging.info('Unable to move SBAC XLSX files to the p-drive, must be connected to the VPN')\n",
    "try:\n",
    "    move_xlsx_files('elpac')\n",
    "    logging.info('Moved ELPAC XLSX files to p-drive')\n",
    "except:\n",
    "    logging.info('Unable to move ELPAC XLSX files to the p-drive, must be connected to the VPN')\n",
    "\n",
    "\n",
    "#Checks these dirs, for all files being there\n",
    "test_instance = TestFileProcessing()\n",
    "test_instance.test_file_processing('sbac')\n",
    "test_instance.test_file_processing('elpac')\n",
    "\n",
    "# #Takes roughly 25 mins to download and send\n",
    "# #Must be connected to the p-drive\n",
    "\n",
    "# ---------------------------------STACKING & SENDING FILES----------------------------------\n",
    "\n",
    "directory_path = r'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing'\n",
    "formatted_month_day_year = today_date.strftime(\"%m_%d_%y\")\n",
    "\n",
    "\n",
    "directory_path_sbac = os.path.join(directory_path, f'sbac_{formatted_month_day_year}')\n",
    "sbac = stack_files(directory_path_sbac)\n",
    "sbac['CALPADSSchoolCode'] = sbac['CALPADSSchoolCode'].astype(str).str[7:]\n",
    "\n",
    "\n",
    "directory_path_elpac = os.path.join(directory_path, f'elpac_{formatted_month_day_year}')\n",
    "elpac = stack_files(directory_path_elpac)\n",
    "elpac['CALPADSSchoolCode'] = elpac['CALPADSSchoolCode'].astype(str).str[7:]\n",
    "\n",
    "sbac = filter_on_full_cds_code(sbac, 'CALPADSSchoolCode')\n",
    "elpac = filter_on_full_cds_code(elpac, 'CALPADSSchoolCode')\n",
    "\n",
    "\n",
    "# -------------------------------------------get_elpac_import------------------\n",
    "elpac = get_elpac_import(elpac)\n",
    "elpac.name = 'ELPAC'\n",
    "directory_path_elpac = os.path.join(directory_path, f'ELPAC_STACKED_{formatted_month_day_year}.csv')\n",
    "try:\n",
    "    elpac.to_csv(directory_path_elpac, index=False)\n",
    "    logging.info(f'ELPAC sent to {directory_path} for ellevation pickup')\n",
    "except:\n",
    "    logging.info(f'ELPAC unable to send for ellevation pickup')\n",
    "\n",
    "\n",
    "#Differing decoding method. Refer to message with Abi\n",
    "# ss_decode = {4.0: 'WelDev', \n",
    "#                 3.0: 'ModDev', \n",
    "#                 2.0: 'SomDev',\n",
    "#                 1.0: 'MinDev', \n",
    "#                 '': 'No Score', \n",
    "#                 'NS': 'No Score'}\n",
    "\n",
    "# -------------------------------Get SBAC import-------------------------\n",
    "\n",
    "#Missing PLScore Column and ProficiencyLevelCode Mapping\n",
    "sbac_final = get_sbac_cols(sbac, 'SBAC')\n",
    "sbac_final.name = 'SBAC'\n",
    "directory_path_sbac = os.path.join(directory_path, f'SBAC_STACKED_{formatted_month_day_year}.csv')\n",
    "try:\n",
    "    sbac_final.to_csv(directory_path_sbac, index=False)\n",
    "    logging.info(f'SBAC sent to {directory_path} for ellevation pickup')\n",
    "except:\n",
    "    logging.info(f'SBAC unable to send for ellevation pickup')\n",
    "\n",
    "# PL Score 1\tSTNM\n",
    "# PL Score 2\tSTNL\n",
    "# PL Score 3\tSTMT\n",
    "# PL Score 4\tSTEX\n",
    "\n",
    "# ------------------------------Get CAST import-------------------------\n",
    "\n",
    "cast = get_cast_cols(sbac, 'CAST')\n",
    "cast.name = 'CAST'\n",
    "directory_path_cast = os.path.join(directory_path, f'CAST_STACKED_{formatted_month_day_year}.csv')\n",
    "try:\n",
    "    cast.to_csv(directory_path_cast, index=False)\n",
    "    logging.info(f'CAST sent to {directory_path} for ellevation pickup')\n",
    "except:\n",
    "    logging.info(f'CAST unable send for ellevation pickup')\n",
    "\n",
    "# PL Score 1\tBLST\n",
    "# PL Score 2\tANST\n",
    "# PL Score 3\tABST\n",
    "\n",
    "# ------------------------------------------------------send to DataTeamSandbox on 89 server-----------------------------\n",
    "\n",
    "quoted = urllib.parse.quote_plus(\"Driver={SQL Server Native Client 11.0};\"\n",
    "                     \"Server=10.0.0.89;\"\n",
    "                     \"Database=DataTeamSandbox;\"\n",
    "                     \"Trusted_Connection=yes;\")\n",
    "\n",
    "engine = sqlalchemy.create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "\n",
    "\n",
    "query_cols = ['Abbreviation',  'StudentNumber', 'SSID', 'TestGrade', 'ELStatus', 'TestDate', \n",
    "            'TestType', 'testname', 'ScaleScore','PLScore', 'ProficiencyLevelCode']\n",
    "\n",
    "blank_cols = ['SchoolID', 'MasterSchoolID', 'StudentID', 'DisplayDate', 'TestPeriod', 'TestScoreType']\n",
    "\n",
    "\n",
    "def obtain_new_scores(file, query_cols, blank_cols):\n",
    "\n",
    "    #cut down current file to non blank cols\n",
    "    file = file[query_cols]\n",
    "\n",
    "    file = file.fillna(0)\n",
    "    query = query.fillna(0)\n",
    "    file = file.replace('NS', 0) #one off exception\n",
    "\n",
    "    file['ScaleScore'] = pd.to_numeric(file['ScaleScore'])\n",
    "    query['ScaleScore'] = pd.to_numeric(query['ScaleScore'])\n",
    "\n",
    "    merging_cols = ['SSID', 'TestType', 'testname', 'ScaleScore']\n",
    "    merged_df = pd.merge(query, file, on=merging_cols, how='left', indicator=True,suffixes=('_query', '_file'))\n",
    "\n",
    "    #insert blank cols\n",
    "\n",
    "    return(merged_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def send_to_SQL(file):\n",
    "\n",
    "\n",
    "    dtypes, table_cols = sql_query_module.SQL_query.get_dtypes(file, 'DataTeamSandbox', f'{file.name}_Scores')\n",
    "\n",
    "    file = obtain_new_scores(file, query_cols, blank_cols)\n",
    "\n",
    "    # elpac.to_sql(f'{file.name}_Scores', schema='dbo', con = engine, if_exists = 'replace', index = False, dtype=dtypes)\n",
    "    # engine.dispose()\n",
    "\n",
    "\n",
    "\n",
    "query = sql_query_module.SQL_query.get_new(f'{file.name}_Scores', query_cols)\n",
    "\n",
    "send_to_SQL(elpac)\n",
    "send_to_SQL(sbac_final)\n",
    "send_to_SQL(cast)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "#What about selecting the initial admin year when switching over Y2Y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "print(password)\n",
    "from modules.login_module import logIn, launch_to_homescreen, create_directory\n",
    "from modules.download_files_module import request_report_process, download_loop_missing, download_process,  move_files_over, unzip_xlsx_file, unzip_files_in_same_dir, move_xlsx_files\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, NoSuchWindowException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules.sql_query_module import SQL_query\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "today_date = datetime.now()\n",
    "formatted_month_day = today_date.strftime(\"%m_%d\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "cast = pd.read_csv('cast.csv')\n",
    "elpac = pd.read_csv('elpac.csv')\n",
    "sbac_final = pd.read_csv('sbac.csv')\n",
    "\n",
    "\n",
    "elpac = Clean(elpac, 'elpac')\n",
    "elpac_clean = elpac.clean_up_rotating_file()\n",
    "\n",
    "file = elpac_clean\n",
    "file_name = 'elpac'\n",
    "\n",
    "\n",
    "dtypes, table_cols = SQL_query.get_dtypes(file, 'DataTeamSandbox', f'{file_name}_Scores')\n",
    "file.to_sql(f'{file_name}_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'append', index = False, dtype=dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "query_cols = ['Abbreviation',  'StudentNumber', 'SSID', 'TestGrade', 'ELStatus', 'TestDate', \n",
    "        'TestType', 'testname', 'ScaleScore','PLScore', 'ProficiencyLevelCode']\n",
    "\n",
    "blank_cols = ['SchoolID', 'MasterSchoolID', 'StudentID', 'DisplayDate', 'TestPeriod', 'TestScoreType']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obtain_new_scores(file, file_name,  query_cols, blank_cols):\n",
    "\n",
    "    \n",
    "    query = SQL_query.get_new(file_name, query_cols)\n",
    "\n",
    "    # query = query.fillna(0)\n",
    "    # file = file.replace('NS', 0) #one off exception\n",
    "\n",
    "    # file['ScaleScore'] = pd.to_numeric(file['ScaleScore'])\n",
    "    # query['ScaleScore'] = pd.to_numeric(query['ScaleScore'])\n",
    "\n",
    "    # merging_cols = ['SSID', 'TestType', 'testname', 'ScaleScore']\n",
    "    # merged_df = pd.merge(query, file, on=merging_cols, how='outer', indicator=True,suffixes=('_query', '_file'))\n",
    "    #If the file is left_only it means the records are only found in query\n",
    "    #If the file is right_only it means the records are only found in file, hence the new records not in the db\n",
    "\n",
    "    return(query)\n",
    "\n",
    "    # new_records = merged_df.loc[merged_df['_merge'] == 'right_only']\n",
    "\n",
    "    # #drop the merge col\n",
    "    # new_records = new_records.drop('_merge', axis=1)\n",
    "\n",
    "    # #Subset the frame down to _file columns\n",
    "    # file_columns = [col for col in list(new_records.columns) if col.endswith(\"_file\")]\n",
    "    # new_records = new_records[file_columns]\n",
    "    \n",
    "    # column_mapping = {col: col.replace('_file', '') for col in new_records.columns}\n",
    "\n",
    "    # #insert blank cols\n",
    "    # for col in blank_cols:\n",
    "    #     new_records[col] = np.nan\n",
    "\n",
    "    # # Rename the columns using the mapping\n",
    "    # new_records = new_records.rename(columns=column_mapping)\n",
    "    # return(new_records)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def send_to_SQL(file, file_name, query_cols, blank_cols):\n",
    "\n",
    "    dtypes, table_cols = SQL_query.get_dtypes(file, 'DataTeamSandbox', f'{file_name}_Scores')\n",
    "\n",
    "    file = obtain_new_scores(file, file_name, query_cols, blank_cols)\n",
    "\n",
    "    return(file)\n",
    "\n",
    "    # if file.empty == True:\n",
    "    #     logging.info(f'No new records to insert, {file_name} file is empty')\n",
    "    # else:\n",
    "    #     file.to_csv(f'file_downloads/{file_name}_new_records.csv')\n",
    "    #     logging.info(f'{file_name}_new_records.csv sent to file downloads')\n",
    "    #     try:\n",
    "    #         file.to_sql(f'{file_name}_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'append', index = False, dtype=dtypes)\n",
    "    #         logging.info(f'Appending {len(file)} to {file_name}_Scores')\n",
    "\n",
    "    #     except Exception as e:\n",
    "    #         logging.info(f'Unable to append to table {file_name}_Scores due to \\n {e}')\n",
    "\n",
    "\n",
    "\n",
    "# file = send_to_SQL(elpac, elpac.name, query_cols, blank_cols)\n",
    "# send_to_SQL(sbac_final, sbac_final.name, query_cols, blank_cols)\n",
    "# send_to_SQL(cast, cast.name, query_cols, blank_cols)\n",
    "\n",
    "#Ok it keeps appending. At this point the records should be in and it should register. Could be an issue with the merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file\n",
    "\n",
    "#So the file columns are the only ones that I want. \n",
    "#Right only means the records are only in the file frame and not in the query frame. \n",
    "#This is what I want. Could be an issue with dtypes. \n",
    "\n",
    "# merging_cols = ['SSID', 'TestType', 'testname', 'ScaleScore']\n",
    "\n",
    "elpac[['SSID', 'TestType', 'testname', 'ScaleScore']].head(40)\n",
    "\n",
    "#Drop rows with no SSID, TestType, testname, ScaleScore\n",
    "\n",
    "# TestType, TestName are strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send this file to Abi. \n",
    "#original name mapping to new columns\n",
    "\n",
    "#Abbreviation - map on CALPADSDIstrictName\n",
    "#schoolid blank\n",
    "#MasterSchoolID blank\n",
    "#StudentNumber - LocalStudentId\n",
    "#StudentID blank\n",
    "#SSID - SSID\n",
    "#TestGrade - GradeAssessed\n",
    "#ELStatus Blank\n",
    "#TestDate - End of the month for the month uploaded\n",
    "#DisplayDate blank\n",
    "#testtype - 21 (General ELPAC) 23(ALT ELPAC)\n",
    "#testperiod blank\n",
    "#testscoretype blank\n",
    "#testname ListeningPL\tSpeakingPL\tReadingPL\tWritingPL \n",
    "#scalescore and plscore melt down\n",
    "#proficiencylevelcode is hard mapping\n",
    "\n",
    "#How often do you need this done?\n",
    "#People dont start asking until end of the testing window, but want a monthly pull. As we lose enrollments of students, we lose access to their scores\n",
    "#End of the month from Feb through May. Last day of Feb.\n",
    "\n",
    "#Prioritize ELPAC pulldowns are Feb-May. \n",
    "#SBAC is April - June (mid) (End of April for SBAC/CAST)\n",
    "\n",
    "#CAST has recordtypes that are taken apart within the SBAC file. \n",
    "\n",
    "#What table do they send it to?\n",
    "# ELPAC [TestScores].[dbo].[vw_rpt_ELPACScores]\n",
    "# CAST  [TestScores].[dbo].[CASTScores]\n",
    "# SBAC: ELA/Math [TestScores].[dbo].[vw_rpt_SBACScores]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
