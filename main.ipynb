{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "from modules.login_module import *\n",
    "from modules.download_files_module import *\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, NoSuchWindowException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules.sql_query_module import SQL_query\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "today_date = datetime.now()\n",
    "formatted_month_day_year = today_date.strftime(\"%m_%d_%y\")\n",
    "download_directory = os.getcwd() + f'\\\\file_downloads\\\\elpac\\\\{formatted_month_day_year}'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "logging.basicConfig(filename='ELPAC_SBAC_results.log', level=logging.INFO,\n",
    "                   format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',force=True)\n",
    "logging.info('\\n\\n-------------ELPAC_SBAC_results new instance log')\n",
    "\n",
    "\n",
    "#clear out download directories prior in the case or re-runs\n",
    "# Example usage\n",
    "\n",
    "sbac_local_dir = fr'C:\\Users\\samuel.taylor\\Desktop\\Python_Scripts\\Manual_Triggers\\ELPAC_SBAC_Results_Selenium\\file_downloads\\sbac\\{formatted_month_day_year}'\n",
    "elpac_local_dir = fr'C:\\Users\\samuel.taylor\\Desktop\\Python_Scripts\\Manual_Triggers\\ELPAC_SBAC_Results_Selenium\\file_downloads\\elpac\\{formatted_month_day_year}'\n",
    "sbac_pdrive_dir = fr'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing\\sbac_{formatted_month_day_year}'\n",
    "elpac_pdrive_dir = fr'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing\\elpac_{formatted_month_day_year}'\n",
    "\n",
    "\n",
    "for i in [sbac_local_dir, elpac_local_dir, sbac_pdrive_dir, elpac_pdrive_dir]:\n",
    "    empty_directory(i)\n",
    "    create_directory(i)\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory' : download_directory,\n",
    "         'profile.default_content_setting_values.automatic_downloads': 1,\n",
    "         'profile.content_settings.exceptions.automatic_downloads.*.setting': 1}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options = chrome_options)\n",
    "\n",
    "\n",
    "def selenium_process(SY):\n",
    "\n",
    "    logIn(username, password, driver)\n",
    "    launch_to_homescreen(driver)\n",
    "\n",
    "    # ---------------------------------------SBAC & ELPAC Files Request and Download-------\n",
    "    # Call the function, school report names variable is called for just school name. MUst occur in this order for Selenium\n",
    "    #Equivalent of Student Score Data File\n",
    "    SBAC_output = SBAC_package_func(driver, SY, 'Tested', formatted_month_day_year)\n",
    "    ELPAC_output = ELPAC_package_func(driver, SY, 'Tested', formatted_month_day_year)\n",
    "\n",
    "    return(SBAC_output, ELPAC_output)\n",
    "\n",
    "SBAC_output, ELPAC_output = selenium_process('2024')\n",
    "\n",
    "# --------------------------------Unzip the XLSX Files and Move them to the P-Drive, Additional Unit Test---------------Path - 'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing'\n",
    "\n",
    "SBAC_output = unzip_move_and_unit(SBAC_output, 'sbac', formatted_month_day_year)\n",
    "ELPAC_output = unzip_move_and_unit(ELPAC_output, 'elpac', formatted_month_day_year)\n",
    "\n",
    "# # ---------------------------------POST SELENIUM PROCESS, STACKING & SENDING FILES----------------------------------\n",
    "\n",
    "sbac_stack = stack_files(sbac_pdrive_dir, 'CAASPP') #This is where files are raw and stacked before transformation\n",
    "elpac_stack = stack_files(elpac_pdrive_dir, 'ELPAC') #Green Dot Schools are pulled out of master file\n",
    "\n",
    "# # -----------------------------Where the normalization of the dataframes occur, column changing & mapping------------------\n",
    "# elpac = get_elpac_import(elpac_stack, 'ELPAC')\n",
    "sbac = get_sbac_import(sbac_stack, 'SBAC')  #For some reason, raw ELPAC file does not have LocalStudentID or studentnumber present for SBAC ELA & Math overall \n",
    "cast = get_cast_import(sbac_stack, 'CAST')\n",
    "\n",
    "# #For Helens Ellevation Pickup, send to same dir as individual files the stack in stacked_files dir\n",
    "# send_stacked_csv(elpac, 'ELPAC', formatted_month_day_year) \n",
    "send_stacked_csv(sbac, 'SBAC', formatted_month_day_year)\n",
    "send_stacked_csv(cast, 'CAST', formatted_month_day_year)\n",
    "\n",
    "# # -----------------------------------------------Send over new records------------------------\n",
    "\n",
    "def send_to_sql(frame, file_name):\n",
    "    dtypes, table_cols = SQL_query.get_dtypes(frame, 'DataTeamSandbox', f'{file_name}_Scores')\n",
    "\n",
    "    # Reference the DataTeamSandbox master tables before they are fully replaced with today's update in order to find the incoming records\n",
    "    #These are populated within the dictionary before the master table is updated. Therefore they are good. \n",
    "    new_records = {\n",
    "        'CAST': grab_new_records(cast, 'CAST'),\n",
    "        # 'ELPAC': grab_new_records(elpac, 'ELPAC'),\n",
    "        'SBAC': grab_new_records(sbac, 'SBAC')\n",
    "    }\n",
    "    \n",
    "    #Update the master table with a full replace, after assessing todays incoming records by each table\n",
    "    try:\n",
    "        frame.to_sql(f'{file_name}_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'replace', index = False, dtype=dtypes)\n",
    "        logging.info(f\"Sent data - {len(frame)} records to master table {file_name}_Scores\")\n",
    "    except Exception as e:\n",
    "        logging.info(f'Unable to send data to {file_name}_Scores due to \\n {e}')\n",
    "\n",
    "    #Update the table with append of only new records, and timestamp it within new_records func\n",
    "    try:\n",
    "        new_records[file_name].to_sql(f'{file_name}_New_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'append', index = False, dtype=dtypes)\n",
    "        logging.info(f\"Sent data to {file_name}_New_Scores, by appending {len(new_records[file_name])} new records\")\n",
    "    except Exception as e:\n",
    "        logging.info(f'Unable to send data to {file_name}_New_Scores due to \\n {e}')\n",
    "\n",
    "\n",
    "#  # OBTAINING NEW RECORDS PROCESS\n",
    "# # The master tables get a full replace with todays data files, however this does not occur until todays data files\n",
    "# # is compared to the master tables. \n",
    "\n",
    "# #Whatever is strictly coming in on the merge from the new frame from these 4 columns will be sent to new scores table\n",
    "# # ['SSID', 'TestType', 'TestName', 'ScaleScore']\n",
    "\n",
    "# #After new scores table is appended with new records with last_update timestamp, the master table gets a full replace of\n",
    "# #todays data files. \n",
    "\n",
    "\n",
    "# send_to_sql(elpac, 'ELPAC')\n",
    "send_to_sql(sbac, 'SBAC')\n",
    "send_to_sql(cast, 'CAST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "from modules.login_module import *\n",
    "from modules.download_files_module import *\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "\n",
    "e = get_elpac_import(elpac_stack, 'ELPAC')\n",
    "\n",
    "es = get_SS_frame(e)\n",
    "ep = get_PL_frame(e)\n",
    "em = pd.merge(ep, es, left_on=['SSID', 'TestName'], right_on = ['SSID', 'TestName'], suffixes= ['', '_SS'], how='left')\n",
    "\n",
    "#Original Frame\n",
    "e = e[['SSID', 'OverallScaleScore', 'OralLanguageScaleScore','WrittenLanguageScaleScore']]\n",
    "e.loc[e['SSID'] == 1367208652]\n",
    "\n",
    "#Melted Frame\n",
    "em = em[['SSID', 'TestName', 'ScaleScore']]\n",
    "em.loc[em['SSID'] == 1367208652]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = pd.merge(ep, es, left_on=['SSID', 'TestName'], right_on = ['SSID', 'TestName'], suffixes= ['', '_SS'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing PL Score ScaleScore Creation for ELPAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "from modules.post_download_change import *\n",
    "\n",
    "\n",
    "\n",
    "sbac_stack = stack_files(sbac_pdrive_dir, 'CAASPP') #This is where files are raw and stacked before transformation\n",
    "elpac_stack = stack_files(elpac_pdrive_dir, 'ELPAC') #Green Dot Schools are pulled out of master file\n",
    "\n",
    "\n",
    "# scale_score = get_SS_frame(elpac_stack)\n",
    "# pl_score = get_PL_frame(elpac_stack)\n",
    "\n",
    "# print(len(scale_score))\n",
    "# print(len(pl_score))\n",
    "\n",
    "\n",
    "\n",
    "# elpac = get_elpac_import(elpac_stack, 'ELPAC')\n",
    "# sbac = get_sbac_import(sbac_stack, 'SBAC')  #For some reason, raw ELPAC file does not have LocalStudentID or studentnumber present for SBAC ELA & Math overall \n",
    "# cast = get_cast_import(sbac_stack, 'CAST')\n",
    "#Look at AchievementLevels for SBAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scale_score['SSID'].unique()))\n",
    "print(len(pl_score['SSID'].unique()))\n",
    "#Multi key dictionary based on all the same SSIDs. \n",
    "\n",
    "\n",
    "# Set multi-index and convert to dictionary\n",
    "scale_score_dict = scale_score.set_index(['SSID', 'TestName'])['ScaleScore'].to_dict()\n",
    "\n",
    "# Function to map ScaleScore using the dictionary\n",
    "def map_scale_score(row, score_dict):\n",
    "    return score_dict.get((row['SSID'], row['TestName']))\n",
    "\n",
    "# Apply the function to create a new ScaleScore column in pl_score DataFrame\n",
    "pl_score['ScaleScore'] = pl_score.apply(map_scale_score, score_dict=scale_score_dict, axis=1)\n",
    "\n",
    "pl_score[['SSID', 'TestName', 'ScaleScore', 'PLScore']].isnull().value_counts()\n",
    "\n",
    "#Still gets the same amount of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_score['ScaleScore'].isnull().value_counts()\n",
    "\n",
    "#Still only 4503 ScaleScores. WHy is that. \n",
    "#Figure out a way to map PL Scores based on something else. \n",
    "\n",
    "#Try on a smaller scale. Try melting down the same frame twice on a smaller scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = elpac_stack[['SSID', 'OverallScaleScore', 'OralLanguageScaleScore','WrittenLanguageScaleScore', 'OverallPL','OralLanguagePL', 'WrittenLanguagePL', 'ListeningPL', 'SpeakingPL', 'ReadingPL', 'WritingPL' ]].head(10)\n",
    "es = get_SS_frame(e)\n",
    "\n",
    "ep = get_PL_frame(es)\n",
    "ep.loc[ep['SSID'] == 1367208652]\n",
    "#This causes repeats of ScaleScores. \n",
    "#SSIDs repeat 21 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running with Todays File Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug get_elpac_import\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Debug get_elpac_import\n",
    "from config import username, password\n",
    "from modules.login_module import *\n",
    "from modules.download_files_module import *\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, NoSuchWindowException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules.sql_query_module import SQL_query\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "today_date = datetime.now()\n",
    "formatted_month_day_year = today_date.strftime(\"%m_%d_%y\")\n",
    "download_directory = os.getcwd() + f'\\\\file_downloads\\\\elpac\\\\{formatted_month_day_year}'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------POST SELENIUM PROCESS, STACKING & SENDING FILES----------------------------------\n",
    "\n",
    "directory_path = r'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing'\n",
    "\n",
    "directory_path_sbac = os.path.join(directory_path, f'sbac_{formatted_month_day_year}')\n",
    "sbac_stack = stack_files(directory_path_sbac)\n",
    "\n",
    "directory_path_elpac = os.path.join(directory_path, f'elpac_{formatted_month_day_year}')\n",
    "elpac_stack = stack_files(directory_path_elpac)\n",
    "\n",
    "elpac_stack = filter_on_full_cds_code(elpac_stack, 'CALPADSSchoolCode')\n",
    "sbac_stack = filter_on_full_cds_code(sbac_stack, 'CALPADSSchoolCode')\n",
    "# elpac_stack = pd.read_csv('file_downloads\\elpac_stack.csv') #For testing purposes to start from this point\n",
    "# sbac_stack = pd.read_csv('file_downloads\\sbac_stack.csv')\n",
    "\n",
    "# -----------------------------Where the normalization of the dataframes occur, column changing & mapping------------------\n",
    "elpac = get_elpac_import(elpac_stack, 'ELPAC')\n",
    "sbac = get_sbac_import(sbac_stack, 'SBAC')  #For some reason, raw ELPAC file does not have LocalStudentID or studentnumber present for SBAC ELA & Math overall \n",
    "cast = get_cast_import(sbac_stack, 'CAST')\n",
    "\n",
    "#For Helens Ellevation Pickup, send to same dir as individual files the stack in stacked_files dir\n",
    "send_stacked_csv(elpac, 'ELPAC', directory_path, formatted_month_day_year) \n",
    "send_stacked_csv(sbac, 'SBAC', directory_path, formatted_month_day_year)\n",
    "send_stacked_csv(cast, 'CAST', directory_path, formatted_month_day_year)\n",
    "\n",
    "# -----------------------------------------------Send over new records------------------------\n",
    "\n",
    "def send_to_sql(frame, file_name):\n",
    "    dtypes, table_cols = SQL_query.get_dtypes(frame, 'DataTeamSandbox', f'{file_name}_Scores')\n",
    "\n",
    "    # Reference the DataTeamSandbox master tables before they are fully replaced with today's update in order to find the incoming records\n",
    "    #These are populated within the dictionary before the master table is updated. Therefore they are good. \n",
    "    new_records = {\n",
    "        'CAST': grab_new_records(cast, 'CAST'),\n",
    "        'ELPAC': grab_new_records(elpac, 'ELPAC'),\n",
    "        'SBAC': grab_new_records(sbac, 'SBAC')\n",
    "    }\n",
    "    \n",
    "    #Update the master table with a full replace, after assessing todays incoming records by each table\n",
    "    try:\n",
    "        frame.to_sql(f'{file_name}_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'replace', index = False, dtype=dtypes)\n",
    "        logging.info(f\"Sent data - {len(frame)} records to master table {file_name}_Scores\")\n",
    "    except Exception as e:\n",
    "        logging.info(f'Unable to send data to {file_name}_Scores due to \\n {e}')\n",
    "\n",
    "    #Update the table with append of only new records, and timestamp it within new_records func\n",
    "    try:\n",
    "        new_records[file_name].to_sql(f'{file_name}_New_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'append', index = False, dtype=dtypes)\n",
    "        logging.info(f\"Sent data to {file_name}_New_Scores, by appending {len(new_records[file_name])} new records\")\n",
    "    except Exception as e:\n",
    "        logging.info(f'Unable to send data to {file_name}_New_Scores due to \\n {e}')\n",
    "\n",
    "\n",
    " # OBTAINING NEW RECORDS PROCESS\n",
    "# The master tables get a full replace with todays data files, however this does not occur until todays data files\n",
    "# is compared to the master tables. \n",
    "\n",
    "#Whatever is strictly coming in on the merge from the new frame from these 4 columns will be sent to new scores table\n",
    "# ['SSID', 'TestType', 'TestName', 'ScaleScore']\n",
    "\n",
    "#After new scores table is appended with new records with last_update timestamp, the master table gets a full replace of\n",
    "#todays data files. \n",
    "\n",
    "\n",
    "send_to_sql(elpac, 'ELPAC')\n",
    "send_to_sql(sbac, 'SBAC')\n",
    "send_to_sql(cast, 'CAST')\n",
    "\n",
    "# Attempting to get files without specifying dates. See if the files come across. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
