{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMUEL~1.TAY\\AppData\\Local\\Temp/ipykernel_14248/1745431191.py:181: DtypeWarning: Columns (31,33,107,108,109,110,115,117,136,138,169,171,175,176,177,178,181,182,183,184,196,197,199,200,201,202,205,206,207,208,209,214,215,220,221,222,223,224,225,226,227,232,233,236,237,238,239,240,241,244,245,248,249,250,254,255,256,257,260,267,268,269,270,275,279,280,281,282,283,284,286,289,290,291,296,297,311,329,366,368,394,396,408,409,414,428,429,430,431,436,437,438,439,460,461,464,466,468,469,470,471,474,475,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sbac_stack = pd.read_csv('file_downloads\\sbac_stack.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Abbreviation', 'schoolid', 'studentnumber', 'SSID', 'TestDate', 'TestType', 'TestPeriod', 'TestSubjectGroup', 'TestGradeLevel', 'TestName', 'ScaleScore', 'PLScore'])\n",
      "cannot insert TestSubjectGroup, already exists\n",
      "cannot insert ProficiencyLevelCode, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Abbreviation', 'schoolid', 'studentnumber', 'SSID', 'TestDate', 'TestType', 'TestPeriod', 'TestSubjectGroup', 'TestGradeLevel', 'TestName', 'ScaleScore', 'PLScore'])\n",
      "cannot insert TestSubjectGroup, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Abbreviation', 'schoolid', 'studentnumber', 'SSID', 'TestDate', 'TestType', 'TestPeriod', 'TestSubjectGroup', 'TestGradeLevel', 'TestName', 'ScaleScore', 'PLScore'])\n",
      "cannot insert TestSubjectGroup, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "from modules.login_module import logIn, launch_to_homescreen, create_directory\n",
    "from modules.download_files_module import request_report_process, download_loop_missing, download_process,  move_files_over, unzip_xlsx_file, unzip_files_in_same_dir, move_xlsx_files\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, NoSuchWindowException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules.sql_query_module import SQL_query\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "today_date = datetime.now()\n",
    "formatted_month_day_year = today_date.strftime(\"%m_%d_%y\")\n",
    "download_directory = os.getcwd() + f'\\\\file_downloads\\\\elpac\\\\{formatted_month_day_year}'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "logging.basicConfig(filename='ELPAC_SBAC_results.log', level=logging.INFO,\n",
    "                   format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',force=True)\n",
    "logging.info('\\n\\n-------------ELPAC_SBAC_results new instance log')\n",
    "\n",
    "#create file_download dir, and establish download directory\n",
    "create_directory('file_downloads')\n",
    "create_directory(f'file_downloads\\\\sbac\\\\{formatted_month_day_year}')\n",
    "create_directory(f'file_downloads\\\\elpac\\\\{formatted_month_day_year}')\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {'download.default_directory' : download_directory,\n",
    "         'profile.default_content_setting_values.automatic_downloads': 1,\n",
    "         'profile.content_settings.exceptions.automatic_downloads.*.setting': 1}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options = chrome_options)\n",
    "\n",
    "logIn(username, password, driver)\n",
    "launch_to_homescreen(driver)\n",
    "\n",
    "coord_list = ['LEA CAASPP Coordinator at Alain Leroy Locke College Preparatory Academy',\n",
    " 'LEA CAASPP Coordinator at Animo City of Champions Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo Compton Charter',\n",
    " 'LEA CAASPP Coordinator at Animo Ellen Ochoa Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Florence-Firestone Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Inglewood Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo Jackie Robinson High',\n",
    " 'LEA CAASPP Coordinator at Animo James B. Taylor Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Jefferson Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Leadership High',\n",
    " 'LEA CAASPP Coordinator at Animo Legacy Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Mae Jemison Charter Middle',\n",
    " 'LEA CAASPP Coordinator at Animo Pat Brown',\n",
    " 'LEA CAASPP Coordinator at Animo Ralph Bunche Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo South Los Angeles Charter',\n",
    " 'LEA CAASPP Coordinator at Animo Venice Charter High',\n",
    " 'LEA CAASPP Coordinator at Animo Watts College Preparatory Academy',\n",
    " 'LEA CAASPP Coordinator at Oscar De La Hoya Animo Charter High',\n",
    " 'LEA ELPAC Coordinator at Alain Leroy Locke College Preparatory Academy',\n",
    " 'LEA ELPAC Coordinator at Animo City of Champions Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo Compton Charter',\n",
    " 'LEA ELPAC Coordinator at Animo Ellen Ochoa Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Florence-Firestone Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Inglewood Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo Jackie Robinson High',\n",
    " 'LEA ELPAC Coordinator at Animo James B. Taylor Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Jefferson Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Leadership High',\n",
    " 'LEA ELPAC Coordinator at Animo Legacy Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Mae Jemison Charter Middle',\n",
    " 'LEA ELPAC Coordinator at Animo Pat Brown',\n",
    " 'LEA ELPAC Coordinator at Animo Ralph Bunche Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo South Los Angeles Charter',\n",
    " 'LEA ELPAC Coordinator at Animo Venice Charter High',\n",
    " 'LEA ELPAC Coordinator at Animo Watts College Preparatory Academy',\n",
    " 'LEA ELPAC Coordinator at Oscar De La Hoya Animo Charter High']\n",
    "\n",
    "elpac_coordinators = [coord for coord in coord_list if 'ELPAC' in coord]\n",
    "caaspp_coordinators = [coord for coord in coord_list if 'CAASPP' in coord]\n",
    "\n",
    "#This exists when passing names into the requested reports, as a subset. Change list into a set to only retain unique schools\n",
    "school_report_names = [entry.split(' at ', 1)[1] for entry in elpac_coordinators]\n",
    "school_report_names = list(set(school_report_names))\n",
    "\n",
    "# ---------------------------------------SBAC Files Request and Download\n",
    "\n",
    "# Call the function, school report names variable is called for just school name\n",
    "#Equivalent of Student Score Data File\n",
    "request_report_process(driver, 'SBAC', 'CAASPP_Student_Score_Data_Extract_Report', caaspp_coordinators, '2023')\n",
    "download_process(school_report_names, '2023 CAASPP Student Score Data File By Enrolled LEA', driver) \n",
    "\n",
    "#This is here three times to see if anything got skipped the first time. Initial dir is set at ELPAC only to move the files over to SBAC dir\n",
    "#Will run 5 times\n",
    "\n",
    "time.sleep(10) #implemented to give time for files to download\n",
    "download_loop_missing(f'elpac\\\\{formatted_month_day_year}', '2023 CAASPP Student Score Data File By Enrolled LEA', driver)\n",
    "\n",
    "#This moves the files from ELPAC  timestamp dir to SBAC timestamp dir. \n",
    "#This is because the download dir cannot be changed in Selenium\n",
    "move_files_over()\n",
    "\n",
    "# --------------------------------------------ELPAC Files Request and Download\n",
    "\n",
    "driver.switch_to.default_content()\n",
    "request_report_process(driver, 'ELPAC', 'Student_Results_Report_Student_Score_Data_Extract', elpac_coordinators, '2023')\n",
    "download_process(school_report_names, '2023 Summative ELPAC and Summative Alternate ELPAC Student Score Data File By Enrolled LEA', driver) \n",
    "\n",
    "time.sleep(10) #implemented to give time for files to download\n",
    "#This is here three times to see if anything got skipped the first time. \n",
    "#Dir remains ELPAC for constant download directory\n",
    "download_loop_missing(f'elpac\\\\{formatted_month_day_year}', '2023 Summative ELPAC and Summative Alternate ELPAC Student Score Data File By Enrolled LEA', driver)\n",
    "\n",
    "#Close out driver window once done\n",
    "driver.close()\n",
    "\n",
    "#Takes 14 mins to run up to this point\n",
    "# -----------------------------------------Unzip the Files and Move them to the P-Drive in this location 'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing'\n",
    "unzip_files_in_same_dir('elpac')\n",
    "unzip_files_in_same_dir('sbac')\n",
    "\n",
    "#Keeps raw zip files in the same dir. Only moves over xlsx files\n",
    "try:\n",
    "    move_xlsx_files('sbac')\n",
    "    logging.info('Moved SBAC XLSX files to p-drive')\n",
    "except:\n",
    "    logging.info('Unable to move SBAC XLSX files to the p-drive, must be connected to the VPN')\n",
    "try:\n",
    "    move_xlsx_files('elpac')\n",
    "    logging.info('Moved ELPAC XLSX files to p-drive')\n",
    "except:\n",
    "    logging.info('Unable to move ELPAC XLSX files to the p-drive, must be connected to the VPN')\n",
    "\n",
    "\n",
    "#Checks these dirs, for all files being there\n",
    "test_instance = TestFileProcessing()\n",
    "test_instance.test_file_processing('sbac')\n",
    "test_instance.test_file_processing('elpac')\n",
    "\n",
    "# #Takes roughly 25 mins to download and send\n",
    "# #Must be connected to the p-drive\n",
    "\n",
    "\n",
    "# ---------------------------------POST SELENIUM PROCESS, STACKING & SENDING FILES----------------------------------\n",
    "\n",
    "# directory_path = r'P:\\Knowledge Management\\Ellevation\\Data Sent 2023-24\\State Testing'\n",
    "\n",
    "# directory_path_sbac = os.path.join(directory_path, f'sbac_{formatted_month_day_year}')\n",
    "# sbac_stack = stack_files(directory_path_sbac)\n",
    "\n",
    "\n",
<<<<<<< Updated upstream
    "directory_path_elpac = os.path.join(directory_path, f'elpac_{formatted_month_day_year}')\n",
    "elpac_stack = stack_files(directory_path_elpac)\n",
=======
    "# directory_path_elpac = os.path.join(directory_path, f'elpac_{formatted_month_day_year}')\n",
    "# elpac_stack = stack_files(directory_path_elpac)\n",
    "\n",
>>>>>>> Stashed changes
    "\n",
    "# elpac_stack = filter_on_full_cds_code(elpac_stack, 'CALPADSSchoolCode')\n",
    "# sbac_stack = filter_on_full_cds_code(sbac_stack, 'CALPADSSchoolCode')\n",
    "\n",
<<<<<<< Updated upstream
    "elpac_stack = filter_on_full_cds_code(elpac_stack, 'CALPADSSchoolCode')\n",
    "sbac_stack = filter_on_full_cds_code(sbac_stack, 'CALPADSSchoolCode')\n",
    "# elpac_stack = pd.read_csv('file_downloads\\elpac_stack.csv') #For testing purposes\n",
    "# sbac_stack = pd.read_csv('file_downloads\\sbac_stack.csv')\n",
=======
    "# #Write files locally, to resume from this point on troubleshoots\n",
    "# sbac_csv_path = f'file_downloads/sbac_stack.csv'\n",
    "# elpac_csv_path = f'file_downloads/elpac_stack.csv'\n",
    "# sbac_stack.to_csv(sbac_csv_path, index=False)\n",
    "# elpac_stack.to_csv(elpac_csv_path, index=False)\n",
    "\n",
    "elpac_stack = pd.read_csv('file_downloads\\elpac_stack.csv')\n",
    "sbac_stack = pd.read_csv('file_downloads\\sbac_stack.csv')\n",
>>>>>>> Stashed changes
    "\n",
    "# -----------------------------Where the normailization of the dataframes occur, column changing & mapping------------------\n",
    "elpac = get_elpac_import(elpac_stack, 'ELPAC')\n",
    "sbac = get_sbac_import(sbac_stack, 'SBAC')  #For some reason, raw ELPAC file does not have LocalStudentID or studentnumber present for SBAC ELA & Math overall \n",
    "cast = get_cast_import(sbac_stack, 'CAST')\n",
    "\n",
    "For Helens Ellevation Pickup.\n",
    "send_stacked_csv(elpac, 'ELPAC', directory_path, formatted_month_day_year) \n",
    "send_stacked_csv(sbac, 'SBAC', directory_path, formatted_month_day_year)\n",
    "send_stacked_csv(cast, 'CAST', directory_path, formatted_month_day_year)\n",
    "\n",
    "# -----------------------------------------------Send over new records------------------------\n",
<<<<<<< Updated upstream
    "#used in combination with obtain_new and clean class to cleanse dtypes, merge and find new records\n",
    "def final(frame, frame_name, append_or_replace):\n",
    "    new_records_elpac = grab_new_records(frame, frame_name) #will return original frame first time\n",
    "    SQL_query.send_to_SQL(new_records_elpac, frame_name, append_or_replace) #dtypes is acquired within function\n",
    "\n",
    "final(elpac, 'ELPAC', 'append')\n",
    "final(cast, 'CAST', 'append')\n",
    "final(sbac, 'SBAC', 'append')\n",
    "\n"
=======
    " #used in combination with obtain_new and clean class to cleanse dtypes, merge and find new records\n",
    "# new_records_cast = grab_new_records(cast, 'CAST') \n",
    "# new_records_elpac = grab_new_records(elpac, 'ELPAC')\n",
    "# new_records_sbac = grab_new_records(sbac, 'SBAC')\n",
    "\n",
    "dtypes, table_cols = SQL_query.get_dtypes(cast, 'DataTeamSandbox', f'CAST_Scores')\n",
    "#Get new_records needs to be independent of the send\n",
    "cast.to_sql(f'CAST_Scores', schema='\n",
    "\n",
    "# SQL_query.send_to_SQL(new_records_cast, 'CAST', 'append')\n",
    "# SQL_query.send_to_SQL(new_records_elpac, 'ELPAC', 'append')\n",
    "# SQL_query.send_to_SQL(new_records_elpac, 'SBAC', 'append')\n",
    "\n",
    "# SQL_query.send_to_SQL(cast, 'CAST', 'append')\n",
    "# SQL_query.send_to_SQL(elpac, 'ELPAC', 'append')\n",
    "# SQL_query.send_to_SQL(cast, 'SBAC', 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMUEL~1.TAY\\AppData\\Local\\Temp/ipykernel_4316/1658727568.py:37: DtypeWarning: Columns (31,33,107,108,109,110,115,117,136,138,169,171,175,176,177,178,181,182,183,184,196,197,199,200,201,202,205,206,207,208,209,214,215,220,221,222,223,224,225,226,227,232,233,236,237,238,239,240,241,244,245,248,249,250,254,255,256,257,260,267,268,269,270,275,279,280,281,282,283,284,286,289,290,291,296,297,311,329,366,368,394,396,408,409,414,428,429,430,431,436,437,438,439,460,461,464,466,468,469,470,471,474,475,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sbac_stack = pd.read_csv('file_downloads\\sbac_stack.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Abbreviation', 'schoolid', 'studentnumber', 'SSID', 'TestDate', 'TestType', 'TestPeriod', 'TestSubjectGroup', 'TestGradeLevel', 'TestName', 'ScaleScore', 'PLScore'])\n",
      "cannot insert TestSubjectGroup, already exists\n",
      "cannot insert ProficiencyLevelCode, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Abbreviation', 'schoolid', 'studentnumber', 'SSID', 'TestDate', 'TestType', 'TestPeriod', 'TestSubjectGroup', 'TestGradeLevel', 'TestName', 'ScaleScore', 'PLScore'])\n",
      "cannot insert TestSubjectGroup, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Abbreviation', 'schoolid', 'studentnumber', 'SSID', 'TestDate', 'TestType', 'TestPeriod', 'TestSubjectGroup', 'TestGradeLevel', 'TestName', 'ScaleScore', 'PLScore'])\n",
      "cannot insert TestSubjectGroup, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaleScore\n",
      "PLScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "from modules.login_module import logIn, launch_to_homescreen, create_directory\n",
    "from modules.download_files_module import request_report_process, download_loop_missing, download_process,  move_files_over, unzip_xlsx_file, unzip_files_in_same_dir, move_xlsx_files\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, NoSuchWindowException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules.sql_query_module import SQL_query\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "today_date = datetime.now()\n",
    "# formatted_month_day_year = today_date.strftime(\"%m_%d_%y\")\n",
    "formatted_month_day_year = '04_26_24'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "elpac_stack = pd.read_csv('file_downloads\\elpac_stack.csv')\n",
    "sbac_stack = pd.read_csv('file_downloads\\sbac_stack.csv')\n",
    "\n",
    "# -----------------------------Where the normailization of the dataframes occur, column changing & mapping------------------\n",
    "elpac = get_elpac_import(elpac_stack, 'ELPAC')\n",
    "sbac = get_sbac_import(sbac_stack, 'SBAC')  #For some reason, raw ELPAC file does not have LocalStudentID or studentnumber present for SBAC ELA & Math overall \n",
    "cast = get_cast_import(sbac_stack, 'CAST')\n",
    "\n",
    "new_records_cast = grab_new_records(cast, 'CAST') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records_cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\ELPAC_SBAC_results_selenium\\modules\\sql_query_module.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con = conn)\n"
     ]
    }
   ],
   "source": [
    "dtypes, table_cols = SQL_query.get_dtypes(cast, 'DataTeamSandbox', f'CAST_Scores')\n",
    "cast.to_sql(f'CAST_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'append', index = False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_update': VARCHAR(length=10)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes, table_cols = SQL_query.get_dtypes(cast, 'DataTeamSandbox', f'CAST_Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main issue is properly sending the dtypes on the second send. \n",
    "#Then I can properly compare the new_records as data types will be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = cast\n",
    "file_name = 'CAST'\n",
    "\n",
    "file_obj = Clean(file, file_name) #This is going to need to have some exceptions based on each file\n",
    "file_obj_clean = file_obj.clean_up_rotating_file()\n",
    "\n",
    "# merging_cols = ['SSID', 'TestType', 'TestName', 'ScaleScore'] #These should work for all 3 files\n",
    "# new_records = SQL_query.obtain_new(file_obj_clean, file_name, merging_cols)\n",
    "\n",
    "#Bring in SQL query\n",
    "query = f'''\n",
    "    SELECT * FROM DataTeamSandbox.dbo.{file_name}_Scores\n",
    "    '''\n",
    "try:\n",
    "    prior = SQL_query.SQL_query_89(query)\n",
    "except DatabaseError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    logging.info(f\"The {file_name} does not exist or there is an issue with the SQL query. Passing obtain new entirely\")\n",
    "    print(f\"The {file_name} does not exist or there is an issue with the SQL query. Passing obtain new entirely\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes, table_cols = SQL_query.get_dtypes(cast, 'DataTeamSandbox', f'CAST_Scores')\n",
    "cast.to_sql(f'CAST_Scores', schema='dbo', con = SQL_query.engine, if_exists = 'replace', index = False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config import username, password\n",
    "from modules.login_module import logIn, launch_to_homescreen, create_directory\n",
    "from modules.download_files_module import request_report_process, download_loop_missing, download_process,  move_files_over, unzip_xlsx_file, unzip_files_in_same_dir, move_xlsx_files\n",
    "from modules.unit_testing import TestFileProcessing\n",
    "from modules.data_transformation import *\n",
    "from modules.post_download_change import *\n",
    "from modules.sql_query_module import *\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from modules.sql_query_module import SQL_query\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "db = 'DataTeamSandbox'\n",
    "table_name_89 = 'CAST_Scores'\n",
    "\n",
    "\n",
    "out = SQL_query.SQL_query_89('''\n",
    "SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH \n",
    "FROM {}.information_schema.columns\n",
    "WHERE table_name = '{}'\n",
    "'''.format(db, table_name_89))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior['ScaleScore'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Stack Raw Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------Where the normailization of the dataframes occur, column changing & mapping------------------\n",
    "\n",
    "# elpac = get_elpac_import(elpac, 'ELPAC')\n",
    "\n",
    "# sbac_final = get_sbac_cols(sbac, 'SBAC', elpac)\n",
    "# cast = get_cast_cols(sbac, 'CAST')\n",
    "\n",
    "#For Helens Ellevation Pickup.\n",
    "# send_stacked_csv(elpac, 'ELPAC', directory_path, formatted_month_day_year) \n",
    "# send_stacked_csv(sbac_final, 'SBAC', directory_path, formatted_month_day_year)\n",
    "# send_stacked_csv(cast, 'CAST', directory_path, formatted_month_day_year)\n",
    "\n",
    "# -----------------------------------------------Send over new records------------------------\n",
    "# new_records = grab_new_records(elpac, 'ELPAC') #used in combination with obtain_new to merge and find new records\n",
    "# SQL_query.send_to_SQL(new_records, 'ELPAC', 'append')\n",
    "\n",
    "# # ------------------------------------------------------send to DataTeamSandbox on 89 server-----------------------------\n",
    "#Might be part of the 'Clean' class\n",
    "# #   insert_blanks = ['SchoolID', 'MasterSchoolID', 'StudentID', 'DisplayDate', 'TestType','TestDate', 'StudentID', 'DisplayDate', 'TestPeriod', 'TestScoreType']\n",
    "\n",
    "# #     for column_name in insert_blanks:\n",
    "# #         df[column_name] = ''\n",
    "\n",
    "#Same for SBAC and ELPAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abi Notes"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the whole thing Selenium to finish and improve logging\n",
    "\n",
    "def download_files(school_name, test_type, driver):\n",
    "    \n",
    "    print(school_name)\n",
    "\n",
    "   # Find the element with the school name & the test_type\n",
    "    school_element = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, f\"//tr[td[text()='{test_type}' and following-sibling::td[text()='{school_name}']]]\"))\n",
    "    )\n",
    "\n",
    "    try:                                                                                                           \n",
    "        download_button = school_element.find_element(By.XPATH, './/input[contains(@class, \"wcag_694 primarybtn left wcag_110\")]')\n",
    "        # Scroll into view\n",
    "        ActionChains(driver).move_to_element(download_button).perform()\n",
    "        logging.info(f'ActionChains scrolled to school {school_name}')\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.info(f'Exception raised when downloading files {e}')\n",
    "\n",
    "    # Click the Download button\n",
    "    try:\n",
    "        download_button.click()\n",
    "        logging.info(f'Download occured for {school_name}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occurred for {school_name}: {str(e)}')\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def download_process(what_schools, test_type, driver):\n",
    "    driver.switch_to.default_content() #only has to happen on reruns technically\n",
    "\n",
    "    for index, school_name in enumerate(what_schools):\n",
    "\n",
    "        if index == 0:\n",
    "\n",
    "            # Wait for the button to be clickable based on text\n",
    "            Requested_Reports = WebDriverWait(driver, 30).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, f'//button[text()=\"Requested Reports\"]'))\n",
    "            )\n",
    "            # Click the button\n",
    "            try:\n",
    "                Requested_Reports.click()\n",
    "                logging.info('Requested reports section clicked into')\n",
    "            except:\n",
    "                pass\n",
    "                logging.info('Requested reports did not get clicked into')\n",
    "\n",
    "            iframe = WebDriverWait(driver, 30).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'theFrame'))\n",
    "            )\n",
    "            #must switch to iframe, HTML page built on encapsulation. \n",
    "            try:\n",
    "                driver.switch_to.frame(iframe)\n",
    "                logging.info('Switched to iframe within downloads section')\n",
    "            except:\n",
    "                pass\n",
    "                logging.info('Failed to switch to iframe within downloads section')\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        download_files(school_name, test_type, driver)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
